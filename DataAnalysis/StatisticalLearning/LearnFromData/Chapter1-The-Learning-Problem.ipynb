{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 The Learning Problem\n",
    "\n",
    "## Problem Setup\n",
    "### Components of Learning\n",
    "The learning algorithm that uses the\n",
    "data set $\\mathrm{D}$ to pick up a formula: $\\mathrm{X} \\rightarrow \\mathrm{Y}$ that approximates $\\mathrm{f}$.\n",
    "\n",
    "The algorithm chooses g from a set of candidate formulas under consideration, which we call the hypothesis set $\\mathrm{H}$.\n",
    "\n",
    "Then the decision for future will be made on $\\mathbf{g}$, not on $\\mathbf{f}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Basic Set up of the learning problem](https://i.loli.net/2019/03/05/5c7dc65b55d32.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple learning model\n",
    "\n",
    "The hypothesis set and learning\n",
    "algorithm are referred to informally as the **learning model**.\n",
    "\n",
    "Let $\\mathcal{X}=\\mathbb{R}^{d}$ be the input space, and $\\mathcal{Y} = \\{+1,-1 \\}$ be the output space,denoting a binary (yes/no) decision.\n",
    "\n",
    "The functional form $h(x)$ that we choose here gives different weights to\n",
    "the different coordinates of x, reflecting their relative importance in the credit\n",
    "decision. The weighted coordinates are then combined to form a 'credit score'\n",
    "and the result is compared to a threshold value. If the applicant passes the\n",
    "threshold, credit is approved; if not, credit is denied:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approve credit if: \n",
    "$$ \n",
    "\\sum_{i=1}^{d} w_{i} x_{i}\n",
    " > threshold\n",
    "$$\n",
    "\n",
    "Deny credit if: \n",
    "$$\n",
    "\\sum_{i=1}^{d} w_{i} x_{i}\n",
    "  < threshold\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This  formula can be written more compactly as\n",
    "$$ \n",
    "h(\\mathbf{x})=\\operatorname{sign}\\left(\\left(\\sum_{i=1}^{d} w_{i} x_{i}\\right)+b\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model of $\\mathcal{H}$ is called the **perceptron**, a name that it got in the context\n",
    "of artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation above can be rewritten as the form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "h(\\mathbf{x})=\\operatorname{sign}\\left(\\mathbf{w}^{\\mathrm{T}} \\mathbf{x}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now introduce the **perceptron learning algorithm (PLA)**. The algorithm\n",
    "will determine what w should be, based on the data. Let us assume that the\n",
    "data set is linearly separable, which means that there is a vector w that\n",
    "makes the equation achieve the correct decision $h (x_n) = Y_n$ on all the training examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update rule is:\n",
    "$$\n",
    "w(t+1) = w(t) + y(t)x(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning verse Design\n",
    "The main difference between the learning approach and the design approach is the role that data plays. In the design approach, the problem is well\n",
    "specified and one can analytically derive $f$ without the need to see any data.\n",
    "In the learning approach, the problem is much less specified, and one needs\n",
    "data to pin down what $f$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Learning\n",
    "### Supervised Learning\n",
    "### Unsurpervised Learning\n",
    "+ Unsupervised learning can be viewed as the task of spontaneously finding patterns and structure in input data.\n",
    "+ Unsupervised learning can also be viewed as a way to create a higher level representation of the data.\n",
    "### Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is Learning Feasible?\n",
    "The target function f is the object of learning. The most important assertion\n",
    "about the target function is that it is unknown. We really mean unknown.\n",
    "\n",
    "This raises a natural question. How could a limited data set reveal enough\n",
    "information to pin down the entire target function?\n",
    "\n",
    "**The chances are the answers were not unanimous, and for good reason.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outside the Data Set\n",
    "![](https://i.loli.net/2019/03/05/5c7dcbe98148a.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as f is an unknown function, knowing V\n",
    "cannot exclude any pattern of values for f outside of V. Therefore, the predictions of g outside of V are meaningless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability to the Rescue\n",
    "We will show that we can indeed infer something outside V using only V, but\n",
    "**in a probabilistic way**. What we infer may not be much compared to learning a full target function, but it will establish the principle that we can reach outside V. Once we establish that, we will take it to the general learning problem and pin down what we can and cannot learn.\n",
    "\n",
    "A random sample from a population\n",
    "tends to agree with the views of the population at large. The probability\n",
    "distribution of the random variable $\\nu$ in terms of the parameter $\\mu$ is well\n",
    "understood, and when the sample size is big, $\\nu$ tends to be close to $\\mu$.\n",
    "\n",
    "To quantify the relationship between $\\nu$ and $\\mu$, we use a simple bound called\n",
    "the *Hoeff ding Inequality*. It states that for any sample size N\n",
    "$$\n",
    "\\mathbb{P}[|\\nu-\\mu|>\\epsilon] \\leq 2 e^{-2 \\epsilon^{2} N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only quantity that is random above is $\\nu$ which depends on the random\n",
    "sample. By contrast, $\\mu$ is not random. It is just a constant, albeit unknown to\n",
    "us. There is a subtle point here. The utility is to infer the value of $\\mu$\n",
    "using the value of $\\nu$, **although it is $\\mu$ that affects $\\nu$, not vice versa**.\n",
    "\n",
    "Notice that only the size N of the sample affects\n",
    "the bound, not the size of the bin. The bin can be large or small, finite or\n",
    "infinite, and we still get the same bound when we use the same sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the bin model relate to the learning problem? It seems that the\n",
    "unknown here was just the value of $\\mu$ while the unknown in learning is an entire function $f : \\mathcal{X} \\rightarrow \\mathcal{Y}$.\n",
    "**The two situations can be connected**. Take any single hypothesis $\\mathcal{h} \\in \\mathcal{H}$ and compare it to $\\mathcal{f}$ on each point $\\mathcal{x} \\in \\mathcal{X}$.\n",
    "If the two equal, color the point green, if not, color the point red.\n",
    "\n",
    "The color that each point gets is not known to us, since f is unknown. However, if we pick x at random according to some probability distribution P over the input\n",
    "space X, we know that x will be red with some probability, call it $\\mu$, and green\n",
    "with probability 1 - $\\mu$. Regardless of the value of $\\mu$, the space X now behaves\n",
    "like the bin in Figure 1.8.\n",
    "\n",
    "![](https://i.loli.net/2019/03/05/5c7dcf37c070f.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training examples play the role of a sample from the bin.\n",
    "If the inputs are picked independently according to P, we will get a random sample of red and green points.\n",
    "Each point will be red with probability Âµ and green with probability $1-\\mu$. The\n",
    "color of each point will be known to us since both $h(x_n)$ and $f(x_n)$ are known\n",
    "( the function h is our hypothesis so we can evaluate it on\n",
    "any point, and $f(x_n) = y_n$ is given to us for all points in the data set V).\n",
    "\n",
    "With this equivalence, the Hoeffding Inequality can be applied to the learn\n",
    "ing problem, allowing us to make a prediction outside of V.\n",
    "\n",
    "Using v to predict $\\mu$ tells us something about f, although it doesn't tell us what f is. What $\\mu$\n",
    "tells us is the error rate h makes in approximating f. If $\\nu$ happens to be close\n",
    "to zero, we can predict that h will approximate f well over the entire input\n",
    "space.\n",
    "\n",
    "Unfortunately, we have no control over $\\nu$ in our current situation, since $\\nu$ is based on a particular hypothesis h. In real learning, we explore an entire\n",
    "hypothesis set $\\mathcal{H}$, looking for some $\\mathcal{h} \\in \\mathcal{H}$ that has a small error rate. If we\n",
    "have only one hypothesis to begin with, we are not really learning, but rather\n",
    "'verifying' whether that particular hypothesis is good or bad.\n",
    "\n",
    "![](https://i.loli.net/2019/03/05/5c7e24a9e1344.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rate within the sample, which\n",
    "corresponds to $\\nu$ in the bin model, will be called the **in-sample error**.\n",
    "\n",
    "\\begin{aligned} E_{\\mathrm{in}}(h) &=(\\text { fraction of } \\mathcal{D} \\text { where } f \\text { and } h \\text { disagree }) \\\\ &=\\frac{1}{N} \\sum_{n=1}^{N}\\left[h\\left(\\mathbf{x}_{n}\\right) \\neq f\\left(\\mathbf{x}_{n}\\right)\\right] \\end{aligned}\n",
    "\n",
    "where $[\\text { statement }]=1$ if the statement is true, and = 0 if the statement is false. Also, we define the **out-of-sample-error**\n",
    "\n",
    "$$ \n",
    "E_{\\mathrm{out}}(h)=\\mathbb{P}[h(\\mathbf{x}) \\neq f(\\mathbf{x})]\n",
    " $$\n",
    " \n",
    "So we get\n",
    "\n",
    "$$ \n",
    "\\mathbb{P}\\left[\\left|E_{\\text { in }}(h)-E_{\\text { out }}(h)\\right|>\\epsilon\\right] \\leq 2 e^{-2 \\epsilon^{2} N}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we move on to an entire hypothesis set $\\mathcal{H}$ instead of just one hypothesis $\\mathcal{h}$, and we assume $\\mathcal{H}$ has a finite number of hypotheses\n",
    "\n",
    "$$ \n",
    "\\mathcal{H}=\\left\\{h_{1}, h_{2}, \\cdots, h_{M}\\right\\}\n",
    "$$\n",
    "\n",
    "We can construct a bin equivalent in this case by having M bins as shown in Figure 1.10.\n",
    "\n",
    "![](https://i.loli.net/2019/03/05/5c7e276b4c0e2.png)\n",
    "\n",
    "Next we need to try to bound $\\mathbb{P}\\left[\\left|E_{\\text { in }}(g)-E_{\\text { out }}(g)\\right|>\\epsilon\\right]$ in a way that does not depend on which g the learning algorithm picks.\n",
    "\n",
    "We get\n",
    "$$ \n",
    "\\begin{aligned} \\mathbb{P}\\left[\\left|E_{\\text { in }}(g)-E_{\\text { out }}(g)\\right|>\\epsilon\\right] \\leq \\mathbb{P}[ &\\left|E_{\\text { in }}\\left(h_{1}\\right)-E_{\\text { out }}\\left(h_{1}\\right)\\right|>\\epsilon \\\\ & \\text { or }\\left|E_{\\text { in }}\\left(h_{2}\\right)-E_{\\text { out }}\\left(h_{2}\\right)\\right|>\\epsilon \\\\ & \\cdots \\\\ & \\text { or }\\left|E_{\\text { in }}\\left(h_{M}\\right)-E_{\\text { out }}\\left(h_{M}\\right)\\right|>\\epsilon ] \\\\ \\leq & \\sum_{m=1}^{M} \\mathbb{P}\\left[\\left|E_{\\text { in }}\\left(h_{m}\\right) \\quad E_{\\text { out }}\\left(h_{m}\\right)\\right|>\\epsilon\\right] \\end{aligned}\n",
    " $$\n",
    "\n",
    "Then\n",
    "\n",
    "$$ \n",
    "\\mathbb{P}\\left[\\left|E_{\\text { in }}(g)-E_{\\text { out }}(g)\\right|>\\epsilon\\right] \\leq 2 M e^{-2 \\epsilon^{2} N}\n",
    " $$\n",
    " \n",
    "This allows the learning algorithm to choose any hypothesis based on $E_{in}$ and expect that the corresponding $E_{out}$ will uniformly follow suit, regardless of which\n",
    "hypothesis is chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feasibility of Learning\n",
    "One argument says that we cannot learn anything outside of $\\mathcal{D}$,\n",
    "and the other says that we can.\n",
    "\n",
    "1. If we insist on a deterministic answer, which means that $\\mathcal{D}$ tells us something certain about $\\mathcal{f}$ outside of $\\mathcal{D}$, then the answer is no. If we accept a probabilistic answer, which means that $\\mathcal{D}$ tells us something likely about $\\mathcal{f}$ outside of $\\mathcal{D}$, then the answer is yes.\n",
    "\n",
    "By adopting the probabilistic view, we get a positive answer to the feasibility\n",
    "question without paying too much of a price. The only assumption we make\n",
    "in the probabilistic framework is that **the examples in \\mathcal{D} are generated independently**.\n",
    "\n",
    "2. Learning produces a hypothesis g to approximate the unknown target function f. If learning is successful, then g should approximate f well, which means $E_{\\mathrm{out}}(g) \\approx 0$. However, this is not what we get from the probabilistic analysis. What we get instead is $E_{\\mathrm{out}}(g) \\approx E_{\\mathrm{in}}(g)$. We still have to make $E_{\\mathrm{in}}(g) \\approx 0$ to conclude that $E_{\\mathrm{out}}(g) \\approx 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One should note that there are cases where we won't insist that $E_{\\mathrm{in}}(g) \\approx 0$\n",
    "\n",
    "Financial forecasting is an example where market unpredictability makes it\n",
    "impossible to get a forecast that has anywhere near zero error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feasibility of learning is thus split into two questions:\n",
    "1. Can we make sure that $E_{\\mathrm{out}}(g)$ is close enough to $E_{\\mathrm{in}}(g)$?\n",
    "2. Can we make $E_{\\mathrm{in}}(g)$ small enough?\n",
    "\n",
    "The Hoeffding Inequality  addresses the first question only. The second\n",
    "question is answered after we run the learning algorithm on the actual data\n",
    "and see how small we can get $E_{in}$ to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The complexity of $\\mathcal{H}$** If the number of hypotheses goes up, we run\n",
    "more risk that $E_{\\mathrm{in}}(g)$ will be a poor estimate of $E_{\\mathrm{out}}(g)$. M can be thought of as a measure of the 'complexity' of the hypothesis set that we use. \n",
    "\n",
    "If we want an affirmative answer to the first\n",
    "question, we need to keep the complexity of H in check. However, if we want\n",
    "an affirmative answer to the second question, we stand a better chance if H\n",
    "is more complex, since g has to come from H. So, a more complex H gives us\n",
    "more flexibility in finding some g that fits the data well, leading to small $E_{\\mathrm{in}}(g)$.\n",
    "\n",
    "The tradeoff in the complexity of H is a major theme in learning theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The complexity of f** Intuitively, a complex target function f should be\n",
    "harder to learn than a simple f. A close look at Inequality reveals that the\n",
    "complexity of f does not affect how well the two errors approximate.\n",
    "\n",
    "If\n",
    "we fix the hypothesis set and the number of training examples, the inequality\n",
    "provides the same bound whether we are trying to learn a simple f (for instance\n",
    "a constant function) or a complex f (for instance a highly nonlinear function).\n",
    "However, this doesn't mean that we can learn complex functions as easily as\n",
    "we learn simple functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error and Noise\n",
    "\n",
    "### Error Measures\n",
    "\n",
    "Learning is not expected to replicate the target function perfectly. The final\n",
    "hypothesis g is only an approximation of\n",
    "f. To quantify how well g approximates\n",
    "f, we need to define an error measure that quantifies how far we are\n",
    "from the target.\n",
    "\n",
    "![](https://i.loli.net/2019/03/05/5c7e2d8241b37.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy Targets\n",
    "\n",
    "In many practical applications, the data we learn from are not generated by\n",
    "a deterministic target function. Instead, they are generated in a noisy way\n",
    "such that the output is not uniquely determined by the input.\n",
    "\n",
    "Instead of $y = f(x)$, we can take the output y to be a random variable\n",
    "that is affected by, rather than determined by, the input x. Formally, we have a target **distribution** $P(y|x)$ instead of a target function.\n",
    "\n",
    "**One can think of a noisy target as a deterministic target plus added noise.**\n",
    "Figure 1.11\n",
    "modifies the previous Figures 1.2 and 1.9 to illustrate the general learning\n",
    "problem, covering both deterministic and noisy targets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a difference between the role of $P(y|x)$ and the role of $P(x)$ in the learning problem. \n",
    "The target distribution $P(y|x)$ is what we are trying to learn, while the input distribution $P(x)$ only quantifies the relative importance of\n",
    "the point x in gauging how well we have learned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
